---
title: "RE_Jobs"
author: "Alan Ponce"
date: "1/27/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
#To clean up the memory of current R session
#rm(list = ls(all=TRUE))

#Libraries
library(tidyverse)
library(devtools)
library(googledrive)
library(gargle)
#library(googlesheets)
library(googlesheets4)

#install_github("dgrtwo/drlib")
#library(drlib)


#Text Mining
library(tidytext)
library(tidyr)
library(stringr)
library(stringi)
library(rebus)
library(wordcloud)
library(SnowballC)
library(textclean)

#NLP
library(rJava)
library(NLP)
library(openNLP)
library(RWeka)
library(qdap)
library(magrittr)

#if (!require("pacman")) install.packages("pacman")
#pacman::p_load_gh("trinker/entity")
#library(entity)



```

## Jobs in Mexico 2022

```{r}
#To clean up the memory of current R session
#rm(list = ls(all=TRUE))


################################## TEST ################################
library(googledrive)

drive_find(n_max = 1)

#name     id                                drive_resource   
#  <chr>    <drv_id>                          <list>           
#1 667BA4B7 1Ge6BlFB_1na7gLI-lr-Syjyhrp_Xh1Pg <named list [42]>

library(googledrive)

# googledrive uses gargle for auth
drive_auth(email = "balanponce@gmail.com")

gs4_auth(
  email = gargle::gargle_oauth_email(),
  path = NULL,
  scopes = "https://www.googleapis.com/auth/spreadsheets",
  cache = gargle::gargle_oauth_cache(),
  use_oob = gargle::gargle_oob_default(),
  token = NULL
)
 
######################################################################
 
# ---- Reading the data
re_jobs_mx <- read_sheet("https://docs.google.com/spreadsheets/d/1S2N51NKerxHVBK2G2kQhnIcbI0FR3WQS3ADWHNJcYkA/edit#gid=0", sheet = "Mexico") 

re_jobs_mx %>% glimpse() %>% View()

# re_jobs_mx <- re_jobs_mx %>% 
#   drop_na()

#re_jobs_mx %>% glimpse() %>% View()

# re_jobs_mx %>% 
#   count(`Student ID`, sort = TRUE)

```


## Detecting patterns

```{r}

################################# Pattern ################################# 

#languages_mx <- c("BPMN", "BPM", "UML", "BABOK",  "procesos", "Agile")

languages_mx <- "BPMN|BPM|UML|BABOK|Agile"
languages_mx

############################## Cleaning the text ############################## 
#tss_ts <- cat(tss_jobs_mx$`Technical skills`)
re_ts_mx <-replace_white(re_jobs_mx$`Technical skills`)


############################## Technical Skills ############################## 
#languages_data <- str_extract_all(re_jobs_mx$`Technical skills`, languages_mx)

languages_mx_data <- str_extract_all(re_ts_mx, languages_mx)
languages_mx_data

languages_mx_data <- unlist(languages_mx_data)
languages_mx_data

languages_data_df <- table(languages_mx_data)
languages_data_df
languages_data_df <- as.data.frame(languages_data_df)
#glimpse(languages_data_df)
#View(languages_data_df)

ggplot(languages_data_df,
            aes(x= reorder(languages_mx_data, -Freq), y=Freq)) +   
            geom_bar(stat = "identity") +
            theme_bw() + 
              geom_bar(stat = "identity", fill="#0072B2", colour="black") +
              geom_text(aes(label=Freq), vjust= -.2, colour="black") +
              xlab("Languages") + ylab("Number of Observations") +
              ggtitle("Jobs in Mexico")  +
              theme(axis.text.x = element_text(angle = 0, hjust = 1))



```

## Jobs in USA

```{r}
#To clean up the memory of current R session
#rm(list = ls(all=TRUE))

# ---- Reading the data
re_jobs_us <- read_sheet("https://docs.google.com/spreadsheets/d/1S2N51NKerxHVBK2G2kQhnIcbI0FR3WQS3ADWHNJcYkA/edit#gid=0", sheet = "US") 

re_jobs_us %>% glimpse() %>% View()

# re_jobs_us <- re_jobs_mx %>% 
#   drop_na()

# re_jobs_us %>% glimpse() %>% View()

```


## Detecting patterns

```{r}
################################# Pattern ################################# 

#languages_us <- c("BPMN", "BPM", "UML", "requirements elicitation", "BABOK", "Agile")

languages_us <- "BPMN|BPM|UML|BABOK|Agile"
languages_us

############################## Cleaning the text ############################## 
#tss_ts <- cat(tss_jobs_mx$`Technical skills`)
re_ts_us <-replace_white(re_jobs_us$`Technical skills`)


############################## Technical Skills ############################## 
#languages_us_data <-  grepl(pattern=languages_us, x= oop_jobs_us$`Technical skills`, fixed=TRUE)
#languages_us_data
#languages_us_data <- str_extract(re_jobs_us$`Technical skills`, languages_us)


languages_us_data <- str_extract_all(re_ts_us, languages_us)
languages_us_data

languages_us_data <- unlist(languages_us_data)
languages_us_data

languages_us_data_df <- table(languages_us_data)
languages_us_data_df
languages_us_data_df <- as.data.frame(languages_us_data_df)
#glimpse(languages_us_data_df)
#View(languages_us_data_df)

ggplot(languages_us_data_df,
            aes(x= reorder(languages_us_data, -Freq), y=Freq)) +   
            geom_bar(stat = "identity") +
            theme_bw() + 
              geom_bar(stat = "identity", fill="#0072B2", colour="black") +
              geom_text(aes(label=Freq), vjust= -.2, colour="black") +
              xlab("Channels") + ylab("Number of Observations") +
              ggtitle("Jobs in USA")  +
              theme(axis.text.x = element_text(angle = 0, hjust = 1))



```

## Text Analysis

### Technical Skills: Top words

```{r}

#Loading stop words
data(stop_words)

#### ---------------Technical Skills 

# "text" is the column name in the dataframe
tidy_re <- re_jobs_us %>%
  unnest_tokens(word, `Technical skills`) %>% 
  anti_join(stop_words)

tidy_re
#View(tidy_re)

# A visualization of the most common words using a theme
tidy_re %>%
  count(word) %>% 
  filter(!word == "NA") %>% 
  top_n(10, n) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(word, n)) +
    geom_col(aes(fill = n), show.legend = FALSE) +
    coord_flip() +
    theme_minimal() +
    ggtitle("Most-used words in Technical Skills") +
    labs(x = NULL, y = "Word frequency", caption = "Post by @alanponce")

# --------- Customize stop words ------

tidy_re_mystopwords <- data_frame(word = c("de",  "building", "required", "understanding", "5"))

tidy_re <- anti_join(tidy_re,
                            tidy_re_mystopwords, by = "word")


# --------- graph most used words ------
tidy_re %>% 
  count(word, sort = TRUE) %>% 
  filter(!word == "NA") %>% 
  top_n(10) %>% 
  ungroup() %>%
  mutate(word = fct_reorder(word, n)) %>% 
    ggplot(aes(word, n)) +
      geom_col(aes(fill = n), show.legend = FALSE) +
      coord_flip() +
      theme_minimal() +
      ggtitle("Most used word by employers") +
      labs(x = NULL, y = "Word frequency", caption = "@alanponce")



```

## Relationships between words: n-grams and correlations:  Biagrams

```{r}

############################### BIGRAMS ########################
## we are examining pairs of two consecutive words, often called “bigrams”
re_bigrams <- re_jobs_us %>%
  unnest_tokens(bigram, `Technical skills`, token = "ngrams", n = 2)

re_bigrams %>% glimpse()

# A visualization of the most common words using bigrams
re_bigrams %>%
  count(bigram, sort = TRUE) %>%
  na.omit() %>%
  top_n(10) %>%
  #filter(n > 1000) %>%
  mutate(bigram = reorder(bigram, n)) %>%
  ggplot(aes(bigram, n)) +
  #geom_col() +
  geom_col(aes(fill = n), show.legend = FALSE) +
  xlab(NULL) +
  coord_flip()

## Let’s remove some of these less meaningful words to make a better, more meaningful plot
tss_bigram_mystopwords <- data_frame(bigram = c("de datos",
                                               "ciencia de",
                                               "learning experience",
                                               "learning and",
                                               "learning frameworks", 
                                               "ci cd",
                                               "NA NA",
                                               "en la", "años de", "en el", "de los",
                                               "experiencia en", "de experiencia"
                                                ))

re_bigrams <- anti_join(re_bigrams,
                                      tss_bigram_mystopwords, by = "bigram")


# A visualization of the most common words using bigrams
re_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% stop_words$word,
          !word2 %in% stop_words$word) %>% 
  #na.omit %>% 
  drop_na(word1) %>% 
  unite("bigram", c(word1, word2), sep = " ") %>%
  count(bigram, sort = TRUE) %>%
  top_n(10) %>%
  mutate(bigram = reorder(bigram, n)) %>%
  ggplot(aes(bigram, n)) +
  geom_col(aes(fill = n), show.legend = FALSE) +
  coord_flip() +
      theme_minimal() +
      ggtitle("Most used bigrams") +
      labs(x = NULL, y = "Word frequency", caption = "@alanponce")


```

## Place

```{r}

re_jobs_mx %>% 
  count(Place) %>% 
  drop_na(Place) %>% 
  arrange(desc(n)) %>% 
  top_n(10, n) %>% 
  mutate(Place = fct_reorder(Place, n)) %>% 
  ggplot(aes(Place, n)) +
    geom_col(aes(fill = n), show.legend = FALSE) +
    coord_flip() +
    theme_minimal() +
    ggtitle("Lugares de trabajo") +
    labs(x = NULL, y = "Observaciones", caption = "Post by @alanponce")

```



### Students contribution

```{r}

# ------------- MX

# --- Student dataframe
re_students_mx <- re_jobs_mx %>% 
  select(`Student ID`) %>% 
  group_by(`Student ID`) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  na.omit() %>% 
  glimpse()

# --- Student graph
ggplot(re_students_mx,
            aes(x= reorder(`Student ID`, -n), y=n)) +   
            geom_bar(stat = "identity") +
            theme_bw() + 
            geom_bar(stat = "identity", fill="#0072B2", colour="black") +
            geom_text(aes(label=n), vjust= -.2, colour="black") +
            xlab("Channels") + ylab("Number of Observations") +
            ggtitle("Student contribution searching in Mexico")  +
            theme(axis.text.x = element_text(angle = 45, hjust = 1))

# ------------- US

# --- Student dataframe
re_students_us <- re_jobs_us %>% 
  select(`Student ID`) %>% 
  group_by(`Student ID`) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  na.omit() %>% 
  glimpse()

# --- Student graph
ggplot(re_students_us,
            aes(x= reorder(`Student ID`, -n), y=n)) +     
            geom_bar(stat = "identity") +
            theme_bw() + 
            geom_bar(stat = "identity", fill="#0072B2", colour="black") +
            geom_text(aes(label=n), vjust= -.2, colour="black") +
            xlab("Channels") + ylab("Number of Observations") +
            ggtitle("Student contribution searching in USA")  +
            theme(axis.text.x = element_text(angle = 45, hjust = 1))
                  

# --- Binding dataframes
re_mx_us_all <- rbind(re_jobs_mx, re_jobs_us) %>% glimpse()

# --- Student dataframe
re_student_contribution <- re_mx_us_all %>% 
  select(`Student ID`) %>% 
  group_by(`Student ID`) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  na.omit() %>% 
  glimpse()


# --- Student graph
ggplot(re_student_contribution,
            aes(x= reorder(`Student ID`, -n), y=n)) +   
            geom_bar(stat = "identity") +
            theme_bw() + 
            geom_bar(stat = "identity", fill="#0072B2", colour="black") +
            geom_text(aes(label=n), vjust= -.2, colour="black") +
            xlab("Participation") + ylab("Number of Observations") +
            ggtitle("Student contribution searching in MX and USA")  +
            theme(axis.text.x = element_text(angle = 45, hjust = 1))






```


















## Jobs in Mexico: DEPRECTED

```{r}

#To clean up the memory of current R session
rm(list = ls(all=TRUE))

# which google sheets do you have access to?
# may ask you to authenticate in a browser!
gs_ls()

#data_googlesheets <- gs_ls()
#data_googlesheets
#View(data_googlesheets)

re_jobs <- gs_title("RE Jobs")
re_jobs
#View(tss_jobs)


#We can "download" one of the sheets using gs_read()
re_jobs_mx <- gs_read(ss=re_jobs, 
                            ws = "Mexico", 
                            skip=0)

re_jobs_mx
glimpse(re_jobs_mx)
View(re_jobs_mx)

```


## Jobs in USA: DEPRECTED

```{r}

#To clean up the memory of current R session
#rm(list = ls(all=TRUE))

# which google sheets do you have access to?
# may ask you to authenticate in a browser!
#gs_ls()

#data_googlesheets <- gs_ls()
#data_googlesheets
#View(data_googlesheets)

#oop_jobs <- gs_title("object oriented programming (OOP)  Jobs")
#oop_jobs
#View(ai_hall_fame)


#We can "download" one of the sheets using gs_read()
re_jobs_us <- gs_read(ss=re_jobs, 
                            ws = "US", 
                            skip=0)

re_jobs_us
glimpse(re_jobs_us)
View(re_jobs_us)


```




